# -*- coding: utf-8 -*-
"""MovieDataset_DownloadAndPreprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HNp--6EzG64dMfxgGRqDqnJdIRtbtC1A
"""

import pandas as pd
import requests
import os
import time

# ==============================
# CONFIG
# ==============================
MAX_MOVIES = 20000   # change if needed
TMDB_API_KEY = "1a1c768f0babc9f17bf0ea5ffcc011f2"
TMDB_BASE_URL = "https://api.themoviedb.org/3"
CACHE_FILE = "tmdb_cache.csv"

# ==============================
# LOAD IMDb DATA
# ==============================
print("Loading IMDb data...")

basics = pd.read_csv(
    "https://datasets.imdbws.com/title.basics.tsv.gz",
    sep="\t",
    compression="gzip",
    na_values="\\N",
    low_memory=False
)

ratings = pd.read_csv(
    "https://datasets.imdbws.com/title.ratings.tsv.gz",
    sep="\t",
    compression="gzip",
    na_values="\\N"
)

movies = basics[
    (basics["titleType"] == "movie") &
    (basics["isAdult"] == 0)
][["tconst", "primaryTitle", "startYear", "genres"]]

movies = movies.merge(ratings, on="tconst", how="left")

movies = movies.dropna(subset=["averageRating", "startYear"])
movies["startYear"] = movies["startYear"].astype(int)

movies.rename(columns={
    "primaryTitle": "title",
    "averageRating": "rating",
    "numVotes": "votes",
    "startYear": "year"
}, inplace=True)

movies["clean_title"] = movies["title"].str.lower().str.strip()
movies = movies.drop_duplicates(subset="clean_title")

# ⭐ LIMIT EARLY (MOST IMPORTANT)
movies = movies.sort_values("votes", ascending=False).head(MAX_MOVIES).reset_index(drop=True)

print(f"Movies selected: {len(movies)}")

# ==============================
# LOAD CACHE
# ==============================
if os.path.exists(CACHE_FILE):
    cache = pd.read_csv(CACHE_FILE)
    cache_dict = dict(zip(cache["tconst"], cache["description"]))
    print("Cache loaded")
else:
    cache_dict = {}

# ==============================
# TMDB SESSION
# ==============================
session = requests.Session()

def get_description(imdb_id):
    if imdb_id in cache_dict:
        return cache_dict[imdb_id]

    try:
        find_url = f"{TMDB_BASE_URL}/find/{imdb_id}"
        find_params = {
            "api_key": TMDB_API_KEY,
            "external_source": "imdb_id"
        }

        find_res = session.get(find_url, params=find_params, timeout=10).json()
        results = find_res.get("movie_results", [])

        if not results:
            cache_dict[imdb_id] = ""
            return ""

        tmdb_id = results[0]["id"]

        movie_url = f"{TMDB_BASE_URL}/movie/{tmdb_id}"
        movie_res = session.get(movie_url, params={"api_key": TMDB_API_KEY}, timeout=10).json()

        desc = movie_res.get("overview", "")
        cache_dict[imdb_id] = desc
        return desc

    except Exception:
        return ""

# ==============================
# FETCH DESCRIPTIONS
# ==============================
print("Fetching TMDB descriptions...")

descriptions = []
for i, imdb_id in enumerate(movies["tconst"], 1):
    descriptions.append(get_description(imdb_id))

    if i % 50 == 0:
        print(f"Processed {i}/{len(movies)}")
        pd.DataFrame(cache_dict.items(), columns=["tconst", "description"]).to_csv(CACHE_FILE, index=False)

movies["description"] = descriptions

# ==============================
# SAVE FINAL CSV
# ==============================
movies.to_csv("movies_with_description.csv", index=False)

print("SUCCESS ✅")
print("Saved: movies_with_description.csv")